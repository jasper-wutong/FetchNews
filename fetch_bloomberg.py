#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å½­åšç¤¾æ–°é—»è·å–å·¥å…·
ç‹¬ç«‹è„šæœ¬ï¼Œå¯ä»¥æ”¾åœ¨ä»»ä½•æ–‡ä»¶å¤¹è¿è¡Œ
åªéœ€è¦å®‰è£… requests åº“: pip install requests

æ³¨æ„ï¼šBloomberg API å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘æ‰èƒ½è®¿é—®
"""

import requests
from datetime import datetime
import json


HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'application/json',
    'Accept-Language': 'en-US,en;q=0.9',
}


def get_markets_news():
    """è·å–Bloombergå¸‚åœºæ–°é—»"""
    url = "https://www.bloomberg.com/lineup/api/lazy_load_paginated_module"
    params = {
        "id": "markets_news",
        "page": 1
    }
    
    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        data = response.json()
        
        news_list = []
        for item in data.get("stories", []):
            # è§£ææ—¶é—´
            time_str = ""
            published = item.get("publishedAt", "")
            if published:
                try:
                    dt = datetime.fromisoformat(published.replace('Z', '+00:00'))
                    time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    time_str = published
            
            news = {
                "id": item.get("id"),
                "title": item.get("headline", ""),
                "url": f"https://www.bloomberg.com{item.get('url', '')}",
                "time": time_str,
                "summary": item.get("summary", "")[:150] if item.get("summary") else ""
            }
            news_list.append(news)
        
        return news_list
    except Exception as e:
        print(f"è·å–å¸‚åœºæ–°é—»å¤±è´¥: {e}")
        return []


def get_top_news():
    """è·å–Bloombergå¤´æ¡æ–°é—»"""
    url = "https://www.bloomberg.com/lineup/api/paginated_stories"
    params = {
        "type": "top_news",
        "page": 1
    }
    
    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        data = response.json()
        
        news_list = []
        for item in data.get("stories", []):
            # è§£ææ—¶é—´
            time_str = ""
            published = item.get("publishedAt", "")
            if published:
                try:
                    dt = datetime.fromisoformat(published.replace('Z', '+00:00'))
                    time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    time_str = published
            
            news = {
                "id": item.get("id"),
                "title": item.get("headline", ""),
                "url": f"https://www.bloomberg.com{item.get('url', '')}",
                "time": time_str,
                "summary": item.get("summary", "")[:150] if item.get("summary") else ""
            }
            news_list.append(news)
        
        return news_list
    except Exception as e:
        print(f"è·å–å¤´æ¡æ–°é—»å¤±è´¥: {e}")
        return []


def get_technology_news():
    """è·å–Bloombergç§‘æŠ€æ–°é—»"""
    url = "https://www.bloomberg.com/lineup/api/lazy_load_paginated_module"
    params = {
        "id": "technology",
        "page": 1
    }
    
    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        data = response.json()
        
        news_list = []
        for item in data.get("stories", []):
            news = {
                "id": item.get("id"),
                "title": item.get("headline", ""),
                "url": f"https://www.bloomberg.com{item.get('url', '')}",
                "time": item.get("publishedAt", ""),
                "summary": item.get("summary", "")[:150] if item.get("summary") else ""
            }
            news_list.append(news)
        
        return news_list
    except Exception as e:
        print(f"è·å–ç§‘æŠ€æ–°é—»å¤±è´¥: {e}")
        return []


def get_bloomberg_rss():
    """é€šè¿‡RSSè·å–Bloombergæ–°é—»ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    url = "https://feeds.bloomberg.com/markets/news.rss"
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=15)
        response.raise_for_status()
        
        # ç®€å•è§£æRSS XML
        import re
        items = re.findall(r'<item>(.*?)</item>', response.text, re.DOTALL)
        
        news_list = []
        for item in items[:20]:
            title = re.search(r'<title>(.*?)</title>', item)
            link = re.search(r'<link>(.*?)</link>', item)
            pubDate = re.search(r'<pubDate>(.*?)</pubDate>', item)
            description = re.search(r'<description>(.*?)</description>', item, re.DOTALL)
            
            news = {
                "title": title.group(1) if title else "",
                "url": link.group(1) if link else "",
                "time": pubDate.group(1) if pubDate else "",
                "summary": description.group(1)[:150] if description else ""
            }
            if news["title"]:
                news_list.append(news)
        
        return news_list
    except Exception as e:
        print(f"è·å–RSSæ–°é—»å¤±è´¥: {e}")
        return []


def print_news(news_list, title):
    """æ ¼å¼åŒ–æ‰“å°æ–°é—»åˆ—è¡¨"""
    print("\n" + "=" * 60)
    print(f"ğŸ“° {title}")
    print("=" * 60)
    
    if not news_list:
        print("æš‚æ— æ•°æ® (å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘)")
        return
    
    for i, news in enumerate(news_list, 1):
        print(f"\n{i}. {news['title']}")
        if news.get('time'):
            print(f"   ğŸ• {news['time']}")
        if news.get('url'):
            print(f"   ğŸ”— {news['url']}")
        if news.get('summary'):
            print(f"   ğŸ“ {news['summary']}...")


def main():
    print("\nğŸŒ Bloombergï¼ˆå½­åšç¤¾ï¼‰æ–°é—»è·å–å·¥å…·")
    print("âš ï¸  æ³¨æ„ï¼šå¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘æ‰èƒ½æ­£å¸¸è®¿é—®")
    print("æ­£åœ¨è·å–æœ€æ–°æ•°æ®...\n")
    
    # å°è¯•è·å–RSSæ–°é—»ï¼ˆæ›´ç¨³å®šï¼‰
    rss_news = get_bloomberg_rss()
    print_news(rss_news[:10], "Bloomberg RSSæ–°é—» (æœ€æ–°10æ¡)")
    
    # å°è¯•è·å–å¸‚åœºæ–°é—»
    markets = get_markets_news()
    print_news(markets[:10], "å¸‚åœºæ–°é—» (æœ€æ–°10æ¡)")
    
    # å°è¯•è·å–å¤´æ¡æ–°é—»
    top = get_top_news()
    print_news(top[:10], "å¤´æ¡æ–°é—» (æœ€æ–°10æ¡)")
    
    print("\n" + "=" * 60)
    print("âœ… è·å–å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
