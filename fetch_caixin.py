#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´¢æ–°ç½‘æ–°é—»è·å–å·¥å…·
ç‹¬ç«‹è„šæœ¬ï¼Œå¯ä»¥æ”¾åœ¨ä»»ä½•æ–‡ä»¶å¤¹è¿è¡Œ
åªéœ€è¦å®‰è£… requests åº“: pip install requests
"""

import requests
from datetime import datetime


HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://www.caixin.com/',
}


def get_latest_articles():
    """è·å–è´¢æ–°ç½‘æœ€æ–°æ–‡ç« """
    url = "https://api.caixin.com/article/hotspot"
    params = {
        "channel": "finance",
        "limit": 30
    }
    
    try:
        response = requests.get(url, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        news_list = []
        for item in data.get("data", []):
            news = {
                "id": item.get("id"),
                "title": item.get("title", ""),
                "url": item.get("url", ""),
                "time": item.get("time", ""),
                "summary": item.get("summary", "")[:100] if item.get("summary") else ""
            }
            if news["title"]:
                news_list.append(news)
        
        return news_list
    except Exception as e:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä»é¦–é¡µHTMLæŠ“å–
        try:
            html_response = requests.get("https://www.caixin.com/", headers=HEADERS, timeout=10)
            html_response.raise_for_status()
            
            import re
            # ä»HTMLä¸­æå–æ–°é—»é“¾æ¥å’Œæ ‡é¢˜
            pattern = r'<a[^>]+href="(https?://[^"]*caixin\.com/[^"]*)"[^>]*>([^<]+)</a>'
            matches = re.findall(pattern, html_response.text)
            
            news_list = []
            seen_titles = set()
            for url, title in matches:
                title = title.strip()
                if title and len(title) > 5 and title not in seen_titles:
                    seen_titles.add(title)
                    news_list.append({
                        "title": title,
                        "url": url,
                        "time": "",
                        "summary": ""
                    })
            
            return news_list[:30]
        except Exception as e2:
            print(f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {e}, å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
            return []


def get_breaking_news():
    """è·å–è´¢æ–°ç½‘é‡‘èæ–°é—»"""
    url = "https://finance.caixin.com/"
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        import re
        # ä»HTMLä¸­æå–æ–°é—»é“¾æ¥å’Œæ ‡é¢˜
        pattern = r'<a[^>]+href="(https?://[^"]*caixin\.com/[^"]*\.html)"[^>]*>([^<]+)</a>'
        matches = re.findall(pattern, response.text)
        
        news_list = []
        seen_titles = set()
        for url, title in matches:
            title = title.strip()
            if title and len(title) > 5 and title not in seen_titles:
                seen_titles.add(title)
                news_list.append({
                    "title": title,
                    "url": url,
                    "time": "",
                    "source": "è´¢æ–°é‡‘è"
                })
        
        return news_list[:30]
    except Exception as e:
        print(f"è·å–é‡‘èæ–°é—»å¤±è´¥: {e}")
        return []


def get_hot_articles():
    """è·å–è´¢æ–°ç½‘å›½é™…æ–°é—»"""
    url = "https://international.caixin.com/"
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        import re
        # ä»HTMLä¸­æå–æ–°é—»é“¾æ¥å’Œæ ‡é¢˜
        pattern = r'<a[^>]+href="(https?://[^"]*caixin\.com/[^"]*\.html)"[^>]*>([^<]+)</a>'
        matches = re.findall(pattern, response.text)
        
        news_list = []
        seen_titles = set()
        for url, title in matches:
            title = title.strip()
            if title and len(title) > 5 and title not in seen_titles:
                seen_titles.add(title)
                news_list.append({
                    "title": title,
                    "url": url,
                    "time": ""
                })
        
        return news_list[:20]
    except Exception as e:
        print(f"è·å–å›½é™…æ–°é—»å¤±è´¥: {e}")
        return []


def print_news(news_list, title):
    """æ ¼å¼åŒ–æ‰“å°æ–°é—»åˆ—è¡¨"""
    print("\n" + "=" * 60)
    print(f"ğŸ“° {title}")
    print("=" * 60)
    
    if not news_list:
        print("æš‚æ— æ•°æ®")
        return
    
    for i, news in enumerate(news_list, 1):
        print(f"\n{i}. {news['title']}")
        if news.get('time'):
            print(f"   ğŸ• {news['time']}")
        if news.get('url'):
            print(f"   ğŸ”— {news['url']}")
        if news.get('summary'):
            print(f"   ğŸ“ {news['summary']}...")


def main():
    print("\nğŸŒ è´¢æ–°ç½‘æ–°é—»è·å–å·¥å…·")
    print("æ­£åœ¨è·å–æœ€æ–°æ•°æ®...\n")
    
    # 1. è·å–ç»æµæ–°é—»
    latest = get_latest_articles()
    print_news(latest[:10], "ç»æµæ–°é—» (æœ€æ–°10æ¡)")
    
    # 2. è·å–é‡‘èæ–°é—»
    breaking = get_breaking_news()
    print_news(breaking[:10], "é‡‘èæ–°é—» (æœ€æ–°10æ¡)")
    
    # 3. è·å–å›½é™…æ–°é—»
    hot = get_hot_articles()
    print_news(hot[:10], "å›½é™…æ–°é—» (æœ€æ–°10æ¡)")
    
    print("\n" + "=" * 60)
    print("âœ… è·å–å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
